import sys
import re
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# é…ç½®å‚æ•°
DEFAULT_MIRROR = "https://hub.docker.lnatic.icu"
TEST_IMAGE = "library/nginx"
TEST_TAG = "latest"
TEST_ARCH = "amd64"
USER_AGENT = "DockerMirrorTester/1.0"
MIN_LAYER_SIZE = 10 * 1024 * 1024  # 10MB
TEST_DATA_SIZE = 10 * 1024 * 1024  # æµ‹è¯•æ•°æ®é‡
CHUNK_SIZE = 1024 * 64  # 64KB
MAX_WORKERS = 10
CACHE_EXPIRE = 300  # è®¤è¯ç¼“å­˜æ—¶é—´(ç§’)
MIN_AVAILABILITY = 95.0


class RegistryAuth:
    def __init__(self):
        self.session = requests.Session()
        self.auth_cache = {}
        self._setup_session()

    def _setup_session(self):
        """é…ç½®ä¼šè¯é‡è¯•ç­–ç•¥"""
        retry = Retry(
            total=3,
            backoff_factor=0.5,
            status_forcelist=[500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry)
        self.session.mount('http://', adapter)
        self.session.mount('https/', adapter)

    def parse_auth_header(self, header):
        """è§£æWWW-Authenticateå¤´"""
        return dict(re.findall(r'(\w+)="([^"]+)"', header))

    def get_registry_token(self, auth_info, repository):
        """è·å–å¹¶ç¼“å­˜Registry Token"""
        cache_key = f"{auth_info['realm']}|{repository}"
        cached = self.auth_cache.get(cache_key)

        if cached and time.time() - cached['timestamp'] < CACHE_EXPIRE:
            return cached['token']

        try:
            params = {
                "service": auth_info.get('service', 'registry.docker.io'),
                "scope": f"repository:{repository}:pull"
            }
            resp = self.session.get(auth_info['realm'], params=params, timeout=5)
            resp.raise_for_status()
            token_data = resp.json()

            self.auth_cache[cache_key] = {
                'token': token_data['token'],
                'timestamp': time.time()
            }
            return token_data['token']
        except Exception as e:
            print(f"ğŸ”‘ è®¤è¯å¤±è´¥: {str(e)}")
            return None


def fetch_mirror_list():
    """è·å–é•œåƒæºå€™é€‰åˆ—è¡¨"""
    print("ğŸ•¸ï¸ æ­£åœ¨è·å–é•œåƒæºåˆ—è¡¨...")
    try:
        resp = requests.get("https://tools.opsnote.top/registry-mirrors/", timeout=10)
        soup = BeautifulSoup(resp.text, 'html.parser')

        mirrors = []
        for item in soup.find_all('div', class_='target-container'):
            url_tag = item.find('h2')
            if not url_tag: continue

            status_tags = item.find_all('div', class_='status-value')
            if len(status_tags) < 3: continue

            try:
                availability = [float(tag.text.strip('%')) for tag in status_tags[:3]]
                if min(availability) >= MIN_AVAILABILITY:
                    mirrors.append(url_tag.text.strip())
            except ValueError:
                continue

        return [urlparse(m).geturl().rstrip('/') for m in mirrors]
    except Exception as e:
        print(f"âš ï¸ é•œåƒæºåˆ—è¡¨è·å–å¤±è´¥: {str(e)}")
        return []


def get_test_layer_digest(auth_handler):
    """è·å–ç”¨äºæµ‹è¯•çš„Layeræ‘˜è¦"""
    print("\nğŸ” æ­£åœ¨é€‰æ‹©æµ‹è¯•å±‚...")
    try:
        registry = "registry-1.docker.io"
        repository = TEST_IMAGE
        tag = TEST_TAG

        # è·å–é•œåƒæ¸…å•
        manifest_url = f"https://{registry}/v2/{repository}/manifests/{tag}"
        headers = {'Accept': 'application/vnd.docker.distribution.manifest.v2+json'}
        resp = auth_handler.session.get(manifest_url, headers=headers)

        # å¤„ç†401è®¤è¯
        if resp.status_code == 401:
            auth_header = resp.headers.get('WWW-Authenticate', '')
            auth_info = auth_handler.parse_auth_header(auth_header)
            token = auth_handler.get_registry_token(auth_info, repository)
            if not token:
                raise PermissionError("æ— æ³•è·å–è®¿é—®ä»¤ç‰Œ")
            headers['Authorization'] = f'Bearer {token}'
            resp = auth_handler.session.get(manifest_url, headers=headers)

        resp.raise_for_status()
        data = resp.json()

        # å¤„ç†å¤šæ¶æ„é•œåƒ
        if 'manifests' in data:
            for manifest in data['manifests']:
                platform = manifest.get('platform', {})
                if platform.get('architecture') == TEST_ARCH and platform.get('os') == 'linux':
                    digest = manifest['digest']
                    # è·å–æ¶æ„ç‰¹å®šæ¸…å•
                    manifest_url = f"https://{registry}/v2/{repository}/manifests/{digest}"
                    resp = auth_handler.session.get(manifest_url, headers=headers)
                    data = resp.json()
                    break

        # é€‰æ‹©ç¬¦åˆæ¡ä»¶çš„Layer
        candidate = None
        for layer in data.get('layers', []):
            if layer['size'] >= MIN_LAYER_SIZE:
                candidate = layer
                break

        # æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„åˆ™é€‰æ‹©æœ€å¤§å±‚
        if not candidate:
            candidate = max(data['layers'], key=lambda x: x['size'])
            print(f"âš ï¸ æ²¡æœ‰è¶³å¤Ÿå¤§çš„å±‚ï¼Œä½¿ç”¨æœ€å¤§å±‚ ({candidate['size'] // 1024 // 1024}MB)")
        else:
            print(f"âœ… é€‰å®šæµ‹è¯•å±‚ ({candidate['size'] // 1024 // 1024}MB)")

        return candidate['digest']
    except Exception as e:
        print(f"âŒ å±‚é€‰æ‹©å¤±è´¥: {str(e)}")
        sys.exit(1)


def test_mirror(auth_handler, mirror_url, layer_digest):
    """æµ‹è¯•å•ä¸ªé•œåƒæºæ€§èƒ½ï¼ˆæ— è¿›åº¦æ¡ç‰ˆï¼‰"""
    try:
        test_url = f"{mirror_url}/v2/{TEST_IMAGE}/blobs/{layer_digest}"
        headers = {'User-Agent': USER_AGENT}
        cache_key = f"{mirror_url}|{TEST_IMAGE}"

        def handle_401(response):
            """ç»Ÿä¸€å¤„ç†401è®¤è¯æµç¨‹"""
            nonlocal headers
            auth_header = response.headers.get('WWW-Authenticate', '')
            if not auth_header:
                return False

            auth_info = auth_handler.parse_auth_header(auth_header)
            token = auth_handler.get_registry_token(auth_info, TEST_IMAGE)
            if not token:
                return False

            headers['Authorization'] = f'Bearer {token}'
            auth_handler.auth_cache[cache_key] = {
                'token': token,
                'timestamp': time.time()
            }
            return True

        # ç¬¬ä¸€æ¬¡HEADè¯·æ±‚è·å–æ–‡ä»¶å¤§å°
        resp = auth_handler.session.head(test_url, headers=headers, timeout=5)
        if resp.status_code == 401 and handle_401(resp):
            resp = auth_handler.session.head(test_url, headers=headers, timeout=5)
        resp.raise_for_status()

        # å¤„ç†æ–‡ä»¶å¤§å°
        total_size = int(resp.headers.get('content-length', 0))
        download_size = min(total_size, TEST_DATA_SIZE)
        if download_size < 1024 * 1024:
            return mirror_url, 0.0, False

        # å‡†å¤‡ä¸‹è½½å‚æ•°
        headers['Range'] = f'bytes=0-{download_size - 1}'
        start_time = time.time()
        downloaded = 0

        # é™é»˜ä¸‹è½½
        with auth_handler.session.get(
                test_url,
                headers=headers,
                stream=True,
                timeout=15
        ) as resp:
            # å¤„ç†ä¸‹è½½æ—¶çš„401
            if resp.status_code == 401 and handle_401(resp):
                resp = auth_handler.session.get(
                    test_url,
                    headers=headers,
                    stream=True,
                    timeout=15
                )
            resp.raise_for_status()

            # åˆ†å—ä¸‹è½½
            for chunk in resp.iter_content(chunk_size=CHUNK_SIZE):
                if chunk:  # è¿‡æ»¤keep-alive chunks
                    downloaded += len(chunk)
                    if downloaded >= download_size:
                        break

        # è®¡ç®—é€Ÿåº¦ï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
        duration = max(time.time() - start_time, 0.001)  # é˜²æ­¢é™¤ä»¥0
        speed = round((downloaded / 1024 / 1024) / duration, 2)
        return mirror_url, speed, True

    except Exception as e:
        print(f"{mirror_url} æµ‹è¯•å¤±è´¥: {str(e)}")
        return mirror_url, 0.0, False


def generate_markdown_table(mirrors):
    """ç”ŸæˆMarkdownè¡¨æ ¼"""
    if not mirrors:
        return "âš ï¸ å½“å‰æ²¡æœ‰å¯ç”¨çš„é•œåƒæºæ•°æ®"

    table = [
        "| æ’å | é•œåƒæºåœ°å€ | å¹³å‡ä¸‹è½½é€Ÿåº¦ |",
        "|------|------------|--------------|"
    ]

    for idx, (url, speed, _) in enumerate(mirrors[:10], 1):
        hostname = urlparse(url).netloc
        table.append(f"| {idx} | `{hostname}` | {speed:.2f} MB/s |")

    return '\n'.join(table)

# æ·»åŠ æ–°çš„ç”ŸæˆREADMEå‡½æ•°
def generate_readme(ranked_mirrors):
    """ç”ŸæˆåŒ…å«é€Ÿåº¦æ’è¡Œçš„README.md"""
    readme_content = f"""# Docker Mirror Benchmark

ğŸš€ è‡ªåŠ¨ç”Ÿæˆçš„é•œåƒæºé€Ÿåº¦æ’è¡Œæ¦œ (æ›´æ–°äº {time.strftime('%Y-%m-%d %H:%M:%S')})

## æµ‹è¯•é•œåƒ
- é•œåƒåç§°: `{TEST_IMAGE}:{TEST_TAG}`
- æµ‹è¯•æ¶æ„: `{TEST_ARCH}`
- æµ‹è¯•æ•°æ®é‡: `{TEST_DATA_SIZE//1024//1024}MB`

## é€Ÿåº¦æ’è¡Œæ¦œ
{generate_markdown_table(ranked_mirrors)}

## é…ç½®è¯´æ˜
ç”Ÿæˆçš„é…ç½®æ–‡ä»¶å·²åŒ…å«ä»¥ä¸‹ä¼˜åŒ–ç­–ç•¥ï¼š
- å‰5ä¸ªæœ€å¿«é•œåƒæº
- æ—¥å¿—é…ç½®ä¼˜åŒ–

"""

def main():
    auth_handler = RegistryAuth()

    # è·å–æµ‹è¯•å±‚æ‘˜è¦
    layer_digest = get_test_layer_digest(auth_handler)

    # è·å–é•œåƒæºåˆ—è¡¨
    mirrors = fetch_mirror_list()
    mirrors.append(DEFAULT_MIRROR)

    # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
    print(f"\nğŸš€ å¼€å§‹æµ‹è¯• {len(mirrors)} ä¸ªé•œåƒæº...")
    results = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = [executor.submit(test_mirror, auth_handler, m, layer_digest) for m in mirrors]

        for future in tqdm(as_completed(futures), total=len(futures), desc="æµ‹è¯•è¿›åº¦"):
            results.append(future.result())

    # å¤„ç†ç»“æœ
    valid_mirrors = sorted(
        [r for r in results if r[2] and r[1] > 0],
        key=lambda x: -x[1]
    )

    # è¾“å‡ºç»“æœ
    print("\nğŸ† é€Ÿåº¦æ’è¡Œæ¦œ (MB/s):")
    for i, (url, speed, _) in enumerate(valid_mirrors[:10], 1):
        print(f"{i:2d}. {urlparse(url).netloc:<25} {speed:.2f} MB/s")

    # ç”Ÿæˆé…ç½®æ–‡ä»¶
    top_mirrors = [m[0] for m in valid_mirrors[:5]]

    # # ç¡®ä¿é»˜è®¤æºåœ¨æœ€å
    # if DEFAULT_MIRROR in top_mirrors:
    #     top_mirrors.remove(DEFAULT_MIRROR)
    # top_mirrors.append(DEFAULT_MIRROR)

    config = {
        "registry-mirrors": top_mirrors,
        "features": {"buildkit": True},
        "log-driver": "json-file",
        "log-opts": {
            "max-size": "100m",
            "max-file": "3",
        }
    }
    with open('daemon.json', 'w') as f:
        json.dump(config, f, indent=2)

    print("\nâœ… é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: daemon.json")
    print("ğŸ”„ è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åº”ç”¨é…ç½®:")
    print(
        "sudo cp daemon.json /etc/docker/daemon.json && sudo systemctl daemon-reload && sudo systemctl restart docker")

if __name__ == "__main__":
    main()
